# 5.1GB
test_url = "https://s3-us-west-1.amazonaws.com/udacity- dlnfd/datasets/skin-cancer/test.zip"
for i, download_link in enumerate([valid_url, train_url, test_url]): temp_file = f"temp{i}.zip"
data_dir = get_file(origin=download_link, fname=os.path.join(os.getcwd(), temp_file))
print("Extracting", download_link)
with zipfile.ZipFile(data_dir, "r") as z: z.extractall("data")
# remove the temp file os.remove(temp_file)

# comment the below line if you already downloaded the dataset download_and_extract_dataset()
# preparing data
# generate CSV metadata file to read img paths and labels from it def generate_csv(folder, label2int):
folder_name = os.path.basename(folder) labels = list(label2int)
# generate CSV file
df = pd.DataFrame(columns=["filepath", "label"]) i = 0
for label in labels:
print("Reading", os.path.join(folder, label, "*"))
for filepath in glob.glob(os.path.join(folder, label, "*")): df.loc[i] = [filepath, label2int[label]]
i += 1
output_file = f"{folder_name}.csv" print("Saving", output_file) df.to_csv(output_file)

# generate CSV files for all data portions, labeling nevus and seborrheic keratosis
# as 0 (benign), and melanoma as 1 (malignant)
# you should replace "data" path to your extracted dataset path
# don't replace if you used download_and_extract_dataset() function generate_csv("data/train", {"nevus": 0, "seborrheic_keratosis": 0,
"melanoma": 1})
generate_csv("data/valid", {"nevus": 0, "seborrheic_keratosis": 0,
"melanoma": 1})
generate_csv("data/test", {"nevus": 0, "seborrheic_keratosis": 0,
"melanoma": 1})
# loading data train_metadata_filename = "train.csv" valid_metadata_filename = "valid.csv" # load CSV files as DataFrames
df_train = pd.read_csv(train_metadata_filename) df_valid = pd.read_csv(valid_metadata_filename) n_training_samples = len(df_train) n_validation_samples = len(df_valid)
print("Number of training samples:", n_training_samples)
print("Number of validation samples:", n_validation_samples)
train_ds = tf.data.Dataset.from_tensor_slices((df_train["filepath"], df_train["label"]))
valid_ds = tf.data.Dataset.from_tensor_slices((df_valid["filepath"], df_valid["label"]))
