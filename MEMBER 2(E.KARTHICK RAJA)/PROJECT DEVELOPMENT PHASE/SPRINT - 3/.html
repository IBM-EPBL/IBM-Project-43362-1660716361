# split to batches
ds = ds.batch(batch_size)
# `prefetch` lets the dataset fetch batches in the background while the model
# is training.
ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE) return ds

valid_ds = prepare_for_training(valid_ds, batch_size=batch_size, cache="valid-cached-data")
train_ds = prepare_for_training(train_ds, batch_size=batch_size, cache="train-cached-data")
batch = next(iter(valid_ds))


def show_batch(batch): plt.figure(figsize=(12,12)) for n in range(25):
ax = plt.subplot(5,5,n+1) plt.imshow(batch[0][n])
plt.title(class_names[batch[1][n].numpy()].title()) plt.axis('off')

show_batch(batch)
# building the model
# InceptionV3 model & pre-trained weights
module_url = "https://tfhub.dev/google/tf2- preview/inception_v3/feature_vector/4"
m = tf.keras.Sequential([
hub.KerasLayer(module_url, output_shape=[2048], trainable=False), tf.keras.layers.Dense(1, activation="sigmoid")
])
model_name = f"benign-vs-malignant_{batch_size}_{optimizer}"
tensorboard = tf.keras.callbacks.TensorBoard(log_dir=os.path.join("logs", model_name))
# saves model checkpoint whenever we reach better weights
modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(model_name + "_{val_loss:.3f}.h5", save_best_only=True, verbose=1)


history = m.fit(train_ds, validation_data=valid_ds,
steps_per_epoch=n_training_samples // batch_size, validation_steps=n_validation_samples // batch_size,
verbose=1, epochs=100,
callbacks=[tensorboard, modelcheckpoint])
if cache:
if isinstance(cache, str): ds = ds.cache(cache)
else:
ds = ds.cache()
ds = ds.shuffle(buffer_size=shuffle_buffer_size) return ds

test_ds = test_ds.map(process_path)
test_ds = prepare_for_testing(test_ds, cache="test-cached-data")
